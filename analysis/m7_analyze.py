# ğŸ“œ analysis/m7_analyze.py
# ğŸ”¬ [ëª¨ë“ˆ 7] KPI í…Œì´ë¸” ë¶„ì„ ë° Metrics ìƒì„±
# (ğŸ”¥ Logging ê¸°ëŠ¥ ì ìš© ë° NaN í”¼ì²˜ ëª©ë¡ ë¡œê¹… ì¶”ê°€)

import pandas as pd
import numpy as np
from omegaconf import DictConfig
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GroupKFold
from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score, accuracy_score
from typing import Dict, Any
import logging  # (ğŸ”¥ ì‹ ê·œ)
import traceback # (ğŸ”¥ ì‹ ê·œ)

# (ğŸ”¥ ì‹ ê·œ) main.pyì—ì„œ ì„¤ì •í•œ ë¡œê±°ë¥¼ ê°€ì ¸ì˜´
logger = logging.getLogger(__name__)

def run_analysis(df: pd.DataFrame, cfg: DictConfig) -> Dict[str, Any]:
    """
    M5ì—ì„œ ìƒì„±ëœ ìµœì¢… KPI DataFrameì„ ì…ë ¥ë°›ì•„,
    readme.md ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ ,
    MLflowì— ë¡œê¹…í•  Metrics ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    - ê²°ì¸¡ì¹˜(NaN/Inf)ê°€ í¬í•¨ëœ í–‰(Epoch)ì€ í†µê³„ ì™œê³¡ì„ ë§‰ê¸° ìœ„í•´ ì œê±°í•©ë‹ˆë‹¤.
    - StandardScalerë¡œ í‘œì¤€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ìœ„í•´ Pipeline ì‚¬ìš©).
    - GroupKFold(groups=df['source_file'])ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼í—˜ì ë…ë¦½ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    - LassoCV (L1 ê·œì œ)ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ ë¶„ë¥˜(church=1 vs market=2)ì—
      ìœ ì˜ë¯¸í•œ KPIë¥¼ ì„ ë³„(Feature Selection)í•˜ê³  êµì°¨ ê²€ì¦ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): M5ì—ì„œ ìƒì„±ëœ KPI í…Œì´ë¸” (final_kpi_df)
        cfg (DictConfig): OmegaConf ì„¤ì • ê°ì²´

    Returns:
        Dict[str, Any]: MLflowì— ë¡œê¹…í•  ì§€í‘œ(metrics) ë”•ì…”ë„ˆë¦¬
    """
    
    # (ğŸ”¥ ìˆ˜ì •) print -> logger.info
    logger.info(f"[M7] KPI í…Œì´ë¸” ë¶„ì„ ë° Metrics ê³„ì‚° ì‹œì‘...")
    metrics = {}
    
    try:
        # --- 1. (ê°€ì´ë“œ 1) ê²°ì¸¡ì¹˜(NaN/Inf) ì²˜ë¦¬ ---
        initial_rows = len(df)
        
        # Inf ê°’ì„ NaNìœ¼ë¡œ ë¨¼ì € ë³€í™˜
        df_with_inf = df.replace([np.inf, -np.inf], np.nan)
        
        # (ğŸ”¥ ì‹ ê·œ) NaN/Inf ë°œìƒ í”¼ì²˜(ì—´) ëª©ë¡ ë¡œê¹…
        nan_features = df_with_inf.columns[df_with_inf.isna().any()].tolist()
        if nan_features:
            logger.warning(f"[M7] NaN ë˜ëŠ” Infê°€ ê°ì§€ëœ KPI(ì—´) ëª©ë¡: {nan_features}")
            # (ì„ íƒ) MLflowì— ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥
            # try:
            #     mlflow.log_text("\n".join(nan_features), "nan_features_list.txt")
            # except Exception:
            #     pass # MLflowê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆì–´ë„ ì˜¤ë¥˜ ë°©ì§€
        
        # NaN ê°’ì„ í¬í•¨í•œ ëª¨ë“  í–‰ ì œê±°
        df_clean = df_with_inf.dropna()
        final_rows = len(df_clean)
        
        metrics['analysis_initial_rows'] = initial_rows
        metrics['analysis_rows_after_nan_drop'] = final_rows
        metrics['analysis_rows_dropped_ratio'] = (initial_rows - final_rows) / (initial_rows + 1e-10)

        if final_rows < 50: # (ì„ê³„ê°’, ì˜ˆ: 50ê°œ)
            # (ğŸ”¥ ìˆ˜ì •) print -> logger.warning
            logger.warning(f"[M7-WARN] ìœ íš¨ ë°ì´í„°(Epoch)ê°€ {final_rows}ê°œë¡œ ë„ˆë¬´ ì ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            metrics['analysis_status'] = "skipped_insufficient_data"
            return metrics

        # --- 2. X (íŠ¹ì§•), y (ë¼ë²¨), groups (íŒŒì¼) ë¶„ë¦¬ ---
        y = df_clean['label']
        groups = df_clean['source_file']
        X = df_clean.drop(columns=['label', 'epoch_id', 'source_file'], errors='ignore') 
        
        if y.nunique() < 2:
            # (ğŸ”¥ ìˆ˜ì •) print -> logger.warning
            logger.warning(f"[M7-WARN] ë¼ë²¨ì´ 1ê°œ ì¢…ë¥˜({y.unique()})ë§Œ ì¡´ì¬í•˜ì—¬ ë¶„ë¥˜ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            metrics['analysis_status'] = "skipped_single_class"
            return metrics

        # --- 3. (ê°€ì´ë“œ 2 & 4) Scikit-learn íŒŒì´í”„ë¼ì¸ ë° GroupKFold ì„¤ì • ---
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('lasso', LassoCV(
                cv=5, 
                random_state=cfg.get('ICA_RANDOM_STATE', 97),
                max_iter=3000,
                n_jobs=-1
            ))
        ])
        
        n_splits = min(max(2, groups.nunique()), 5)
        gkf = GroupKFold(n_splits=n_splits)
        
        f1_scores = []
        acc_scores = []

        # (ğŸ”¥ ìˆ˜ì •) print -> logger.info
        logger.info(f"[M7] GroupKFold (n_splits={n_splits}) êµì°¨ ê²€ì¦ ì‹œì‘...")
        
        for train_idx, test_idx in gkf.split(X, y, groups):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            
            pipeline.fit(X_train, y_train)
            
            preds_float = pipeline.predict(X_test)
            preds_binary_label = [2 if p > 1.5 else 1 for p in preds_float]
            
            f1_scores.append(f1_score(y_test, preds_binary_label, average='weighted', zero_division=0))
            acc_scores.append(accuracy_score(y_test, preds_binary_label))

        # --- 4. ìµœì¢… Metrics ê³„ì‚° ---
        metrics['analysis_cv_f1_mean'] = np.mean(f1_scores)
        metrics['analysis_cv_f1_std'] = np.std(f1_scores)
        metrics['analysis_cv_accuracy_mean'] = np.mean(acc_scores)
        metrics['analysis_cv_accuracy_std'] = np.std(acc_scores)

        # (ğŸ”¥ ìˆ˜ì •) print -> logger.info
        logger.info(f"[M7] CV F1-Score (Mean): {metrics['analysis_cv_f1_mean']:.4f}")

        # --- 5. (ê°€ì´ë“œ 4) ìµœì¢… ëª¨ë¸ í”¼ì²˜ ì„ ë³„ ---
        pipeline.fit(X, y) 
        lasso_model = pipeline.named_steps['lasso']
        
        importances = np.abs(lasso_model.coef_)
        selected_features_mask = importances > 1e-5
        n_selected = np.sum(selected_features_mask)
        
        metrics['analysis_lasso_features_selected'] = int(n_selected)
        metrics['analysis_lasso_total_features'] = len(importances)
        
        # (ğŸ”¥ ìˆ˜ì •) print -> logger.info
        logger.info(f"[M7] Lasso ì„ ë³„ í”¼ì²˜ ê°œìˆ˜: {n_selected} / {len(importances)}")

        try:
            top_5_indices = np.argsort(importances)[-5:][::-1]
            top_5_features = X.columns[top_5_indices].tolist()
            # (ğŸ”¥ ìˆ˜ì •) print -> logger.info
            logger.info(f"[M7] Top 5 Features: {top_5_features}")
            
            metrics['analysis_top_1_feature'] = top_5_features[0] if n_selected > 0 else "None"
            metrics['analysis_top_2_feature'] = top_5_features[1] if n_selected > 1 else "None"
            
        except Exception as e:
            # (ğŸ”¥ ìˆ˜ì •) print -> logger.warning
            logger.warning(f"[M7-WARN] Top í”¼ì²˜ ì´ë¦„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        metrics['analysis_status'] = "completed"

    except Exception as e:
        # (ğŸ”¥ ìˆ˜ì •) print -> logger.error
        logger.error(f"[ERROR M7] KPI ë¶„ì„ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # (ğŸ”¥ ìˆ˜ì •) traceback.print_exc() -> logger.error()
        logger.error(traceback.format_exc())
        metrics['analysis_status'] = "failed"
        
    return metrics