# ğŸ“œ analysis/m7_analyze.py
# ğŸ”¬ [ëª¨ë“ˆ 7] KPI í…Œì´ë¸” ë¶„ì„ ë° Metrics ìƒì„±
# (readme.mdì˜ "ìµœì¢… ë¶„ì„ ê°€ì´ë“œ"ë¥¼ ê¸°ë°˜ìœ¼ë¡œ MLflow ë¡œê¹…ìš© ì§€í‘œë¥¼ ê³„ì‚°)

import pandas as pd
import numpy as np
from omegaconf import DictConfig
from sklearn.linear_model import LassoCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GroupKFold
from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score, accuracy_score
from typing import Dict, Any

def run_analysis(df: pd.DataFrame, cfg: DictConfig) -> Dict[str, Any]:
    """
    M5ì—ì„œ ìƒì„±ëœ ìµœì¢… KPI DataFrameì„ ì…ë ¥ë°›ì•„,
    readme.md ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ ,
    MLflowì— ë¡œê¹…í•  Metrics ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    - ê²°ì¸¡ì¹˜(NaN/Inf)ê°€ í¬í•¨ëœ í–‰(Epoch)ì€ í†µê³„ ì™œê³¡ì„ ë§‰ê¸° ìœ„í•´ ì œê±°í•©ë‹ˆë‹¤.
    - StandardScalerë¡œ í‘œì¤€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ìœ„í•´ Pipeline ì‚¬ìš©).
    - GroupKFold(groups=df['source_file'])ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼í—˜ì ë…ë¦½ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    - LassoCV (L1 ê·œì œ)ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ ë¶„ë¥˜(church=1 vs market=2)ì—
      ìœ ì˜ë¯¸í•œ KPIë¥¼ ì„ ë³„(Feature Selection)í•˜ê³  êµì°¨ ê²€ì¦ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        df (pd.DataFrame): M5ì—ì„œ ìƒì„±ëœ KPI í…Œì´ë¸” (final_kpi_df)
        cfg (DictConfig): OmegaConf ì„¤ì • ê°ì²´

    Returns:
        Dict[str, Any]: MLflowì— ë¡œê¹…í•  ì§€í‘œ(metrics) ë”•ì…”ë„ˆë¦¬
    """
    
    print(f"[M7] KPI í…Œì´ë¸” ë¶„ì„ ë° Metrics ê³„ì‚° ì‹œì‘...")
    metrics = {}
    
    try:
        # --- 1. (ê°€ì´ë“œ 1) ê²°ì¸¡ì¹˜(NaN/Inf) ì²˜ë¦¬ ---
        # 0ì´ë‚˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ì§€ ì•Šê³ , í•´ë‹¹ í–‰(Epoch)ì„ ì œê±°
        initial_rows = len(df)
        # Inf ê°’ì„ NaNìœ¼ë¡œ ë¨¼ì € ë³€í™˜
        df_clean = df.replace([np.inf, -np.inf], np.nan)
        # NaN ê°’ì„ í¬í•¨í•œ ëª¨ë“  í–‰ ì œê±°
        df_clean = df_clean.dropna()
        final_rows = len(df_clean)
        
        metrics['analysis_initial_rows'] = initial_rows
        metrics['analysis_rows_after_nan_drop'] = final_rows
        metrics['analysis_rows_dropped_ratio'] = (initial_rows - final_rows) / (initial_rows + 1e-10)

        if final_rows < 50: # (ì„ê³„ê°’, ì˜ˆ: 50ê°œ)
            print(f"[M7-WARN] ìœ íš¨ ë°ì´í„°(Epoch)ê°€ {final_rows}ê°œë¡œ ë„ˆë¬´ ì ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            metrics['analysis_status'] = "skipped_insufficient_data"
            return metrics

        # --- 2. X (íŠ¹ì§•), y (ë¼ë²¨), groups (íŒŒì¼) ë¶„ë¦¬ ---
        
        # y: ë¼ë²¨ (1 ë˜ëŠ” 2)
        y = df_clean['label']
        
        # groups: (ê°€ì´ë“œ 3) í”¼í—˜ì ë…ë¦½ì„±ì„ ìœ„í•œ íŒŒì¼ ì´ë¦„
        groups = df_clean['source_file']
        
        # X: KPI íŠ¹ì§•ë“¤ (ë¼ë²¨, ID, íŒŒì¼ëª… ë“± ë¹„-íŠ¹ì§• ì—´ ì œì™¸)
        # (errors='ignore'ëŠ” í˜¹ì‹œ ì—´ì´ ì—†ë”ë¼ë„ ì˜¤ë¥˜ë¥¼ ë‚´ì§€ ì•ŠìŒ)
        X = df_clean.drop(columns=['label', 'epoch_id', 'source_file'], errors='ignore') 
        
        # (ì¤‘ìš”) ë¼ë²¨ì´ 2ê°œ(church, market)ì¸ì§€ í™•ì¸
        if y.nunique() < 2:
            print(f"[M7-WARN] ë¼ë²¨ì´ 1ê°œ ì¢…ë¥˜({y.unique()})ë§Œ ì¡´ì¬í•˜ì—¬ ë¶„ë¥˜ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            metrics['analysis_status'] = "skipped_single_class"
            return metrics

        # --- 3. (ê°€ì´ë“œ 2 & 4) Scikit-learn íŒŒì´í”„ë¼ì¸ ë° GroupKFold ì„¤ì • ---
        
        # (ê°€ì´ë“œ 2) ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ Pipeline ë‚´ì—ì„œ Scaler ì‚¬ìš©
        # (ê°€ì´ë“œ 4) LassoCVë¡œ ìë™ í”¼ì²˜ ì„ ë³„
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('lasso', LassoCV(
                # (1 vs 2 ë¼ë²¨ì´ë¯€ë¡œ) 1.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” íšŒê·€ ëª¨ë¸ ì‚¬ìš©
                cv=5, # Lasso ë‚´ë¶€ì˜ ìµœì  alpha íƒìƒ‰ìš© CV
                random_state=cfg.get('ICA_RANDOM_STATE', 97), # configì—ì„œ ëœë¤ ì‹œë“œ ê°€ì ¸ì˜¤ê¸°
                max_iter=3000, # ìˆ˜ë ´ì„ ìœ„í•œ ë°˜ë³µ íšŸìˆ˜ ì¦ê°€
                n_jobs=-1 # ëª¨ë“  CPU ì‚¬ìš©
            ))
        ])
        
        # (ê°€ì´ë“œ 3) í”¼í—˜ì(íŒŒì¼) ë…ë¦½ì  êµì°¨ ê²€ì¦
        # (ìµœì†Œ 2ê°œ, ìµœëŒ€ 5ê°œ ë˜ëŠ” íŒŒì¼ ê°œìˆ˜ë§Œí¼ KFold ìˆ˜í–‰)
        n_splits = min(max(2, groups.nunique()), 5)
        gkf = GroupKFold(n_splits=n_splits)
        
        f1_scores = []
        acc_scores = []

        print(f"[M7] GroupKFold (n_splits={n_splits}) êµì°¨ ê²€ì¦ ì‹œì‘...")
        
        for train_idx, test_idx in gkf.split(X, y, groups):
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            
            pipeline.fit(X_train, y_train)
            
            # LassoëŠ” íšŒê·€ ëª¨ë¸ì´ë¯€ë¡œ ì˜ˆì¸¡ê°’(ì˜ˆ: 1.1, 1.9)ì„ ë¼ë²¨(1, 2)ë¡œ ë³€í™˜
            preds_float = pipeline.predict(X_test)
            # 1.5ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 1(church)ê³¼ 2(market)ë¡œ ë³€í™˜
            preds_binary_label = [2 if p > 1.5 else 1 for p in preds_float]
            
            f1_scores.append(f1_score(y_test, preds_binary_label, average='weighted', zero_division=0))
            acc_scores.append(accuracy_score(y_test, preds_binary_label))

        # --- 4. ìµœì¢… Metrics ê³„ì‚° ---
        metrics['analysis_cv_f1_mean'] = np.mean(f1_scores)
        metrics['analysis_cv_f1_std'] = np.std(f1_scores)
        metrics['analysis_cv_accuracy_mean'] = np.mean(acc_scores)
        metrics['analysis_cv_accuracy_std'] = np.std(acc_scores)

        print(f"[M7] CV F1-Score (Mean): {metrics['analysis_cv_f1_mean']:.4f}")

        # --- 5. (ê°€ì´ë“œ 4) ìµœì¢… ëª¨ë¸ í”¼ì²˜ ì„ ë³„ ---
        # ì „ì²´ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ì¬í•™ìŠµ (ìµœì ì˜ í”¼ì²˜ ì°¾ê¸° ìœ„í•´)
        pipeline.fit(X, y) 
        
        # í•™ìŠµëœ Lasso ëª¨ë¸ ì ‘ê·¼
        lasso_model = pipeline.named_steps['lasso']
        
        # (Lassoê°€ 0ì´ ì•„ë‹Œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•œ) ì¤‘ìš” í”¼ì²˜ ì¶”ì¶œ
        importances = np.abs(lasso_model.coef_)
        selected_features_mask = importances > 1e-5 # (0ì— ë§¤ìš° ê°€ê¹Œìš´ ê°’ ì œì™¸)
        n_selected = np.sum(selected_features_mask)
        
        metrics['analysis_lasso_features_selected'] = int(n_selected)
        metrics['analysis_lasso_total_features'] = len(importances)
        
        print(f"[M7] Lasso ì„ ë³„ í”¼ì²˜ ê°œìˆ˜: {n_selected} / {len(importances)}")

        # (ì„ íƒ) MLflowì— ìƒìœ„ 5ê°œ í”¼ì²˜ ì´ë¦„ ë¡œê¹… (log_paramì€ ë¬¸ìì—´ 250ì ì œí•œ, log_textëŠ” ë¬´ì œí•œ)
        try:
            top_5_indices = np.argsort(importances)[-5:][::-1]
            top_5_features = X.columns[top_5_indices].tolist()
            # (MLflowì—ì„œëŠ” log_textë¥¼ ì‚¬ìš©í•´ì•¼ í•¨. ì—¬ê¸°ì„œëŠ” printë¡œ ëŒ€ì²´)
            print(f"[M7] Top 5 Features: {top_5_features}")
            # (main.pyì—ì„œ mlflow.log_text(..., "top_features.txt")ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜
            #  metrics ë”•ì…”ë„ˆë¦¬ì— ë¬¸ìì—´ë¡œ ì¶”ê°€ - ë‹¨, 250ì ì œí•œ ì£¼ì˜)
            metrics['analysis_top_1_feature'] = top_5_features[0] if n_selected > 0 else "None"
            metrics['analysis_top_2_feature'] = top_5_features[1] if n_selected > 1 else "None"
            
        except Exception as e:
            print(f"[M7-WARN] Top í”¼ì²˜ ì´ë¦„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        metrics['analysis_status'] = "completed"

    except Exception as e:
        print(f"[ERROR M7] KPI ë¶„ì„ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        metrics['analysis_status'] = "failed"
        
    return metrics